{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = 'sonycnode-b827eb86d458.sonyc'\n",
    "node3 = 'sonycnode-b827ebb40450.sonyc'\n",
    "node4 = 'sonycnode-b827eb73e772.sonyc'\n",
    "\n",
    "path1 = f'../sonyc/spl/2017/{node1}.h5'\n",
    "path3 = f'../sonyc/spl/2017/{node3}.h5'\n",
    "path4 = f'../sonyc/spl/2017/{node4}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start, train_end = pd.Timestamp('2017-04-01'), pd.Timestamp('2017-07-01')\n",
    "test_start, test_end = pd.Timestamp('2017-07-01'), pd.Timestamp('2017-08-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_spl_data(path):\n",
    "    df = pd.read_hdf(path, key='minute_intervals')\n",
    "    df = df[df['timestamp'] < 1514764800] # remove any 2018 values\n",
    "    df['datetime[utc]'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    \n",
    "    return df[['datetime[utc]', 'dBAS_mean']]\n",
    "\n",
    "def reduce_spl_data(df, start, end):\n",
    "    # reduced data to mean of a given hourly interval\n",
    "    reduced_df = df[\n",
    "        (start <= df['datetime[utc]']) & \n",
    "        (df['datetime[utc]'] < end) &\n",
    "        (df['datetime[utc]'].dt.minute == 51)\n",
    "    ].reset_index(drop=True)\n",
    "    \n",
    "    grouped_df = reduced_df.groupby([\n",
    "        reduced_df['datetime[utc]'].dt.month,\n",
    "        reduced_df['datetime[utc]'].dt.day,\n",
    "        reduced_df['datetime[utc]'].dt.hour]\n",
    "    ).mean()\n",
    "    \n",
    "    new_date_col = (grouped_df\n",
    "        .index\n",
    "        .to_series()\n",
    "        .apply(lambda t: pd.Timestamp(*((2017,) + t + (51,))))\n",
    "        .reset_index(drop=True))\n",
    "    \n",
    "    grouped_df.reset_index(drop=True, inplace=True)\n",
    "    grouped_df['datetime[utc]'] = new_date_col\n",
    "\n",
    "    return grouped_df[['datetime[utc]', 'dBAS_mean']]\n",
    "\n",
    "# load spl stuff\n",
    "spl1_df = load_spl_data(path1)\n",
    "reduced_spl1_df = reduce_spl_data(spl1_df, train_start, test_end)\n",
    "\n",
    "spl3_df = load_spl_data(path3)\n",
    "reduced_spl3_df = reduce_spl_data(spl3_df, train_start, test_end)\n",
    "\n",
    "spl4_df = load_spl_data(path4)\n",
    "reduced_spl4_df = reduce_spl_data(spl4_df, train_start, test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weather stuff\n",
    "weather_df = pd.read_csv(\n",
    "    '../data/weather.csv', \n",
    "    usecols=['datetime[utc]', 'precipitation[mm]'], \n",
    "    parse_dates=['datetime[utc]']\n",
    ")\n",
    "\n",
    "reduced_weather_df = weather_df[\n",
    "    (train_start <= weather_df['datetime[utc]']) & \n",
    "    (weather_df['datetime[utc]'] < test_end) &\n",
    "    (weather_df['datetime[utc]'].dt.minute == 51) # only using this rolling window\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: verify later that each hour is also represented\n",
    "def merge_dfs(weather_df, spl_df):\n",
    "    working_df = pd.merge(weather_df, spl_df, how='outer', on='datetime[utc]').sort_values(by='datetime[utc]')\n",
    "\n",
    "    if any(working_df['precipitation[mm]'].isna()):\n",
    "        print(f\"{len(working_df[working_df['precipitation[mm]'].isna()])} NaNs in 'precipitation[mm],' replacing them with 0.0\")\n",
    "        working_df.loc[working_df[working_df['precipitation[mm]'].isna()].index, 'precipitation[mm]'] = 0.0\n",
    "\n",
    "    if any(working_df['dBAS_mean'].isna()):\n",
    "        avg = working_df['dBAS_mean'].dropna().mean()\n",
    "        print(f\"{len(working_df[working_df['dBAS_mean'].isna()])} NaNs in 'dBAS_mean,' replacing them with {avg}\")\n",
    "        working_df.loc[working_df[working_df['dBAS_mean'].isna()].index, 'dBAS_mean'] = avg\n",
    "        \n",
    "    # add rained class\n",
    "    working_df['rained'] = (working_df['precipitation[mm]'] > 0.00).astype(int)\n",
    "        \n",
    "    return working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df1 = merge_dfs(reduced_weather_df, reduced_spl1_df)\n",
    "merged_df3 = merge_dfs(reduced_weather_df, reduced_spl3_df)\n",
    "merged_df4 = merge_dfs(reduced_weather_df, reduced_spl4_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all_df = merged_df1.copy()\n",
    "merged_all_df.rename(columns={'dBAS_mean': 'dBAS_mean_01'}, inplace=True)\n",
    "merged_all_df['dBAS_mean_03'] = merged_df3['dBAS_mean']\n",
    "merged_all_df['dBAS_mean_04'] = merged_df4['dBAS_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: time independent\n",
    "def sep_train_test_data(merged_df, training_int, testing_int):\n",
    "    train_start, train_end = training_int\n",
    "    test_start, test_end = testing_int\n",
    "    \n",
    "    training_cla_df = merged_df[\n",
    "        (train_start <= merged_df['datetime[utc]']) & \n",
    "        (merged_df['datetime[utc]'] < train_end)\n",
    "    ][['rained', 'dBAS_mean']]\n",
    "\n",
    "    testing_cla_df = merged_df[\n",
    "        (test_start <= merged_df['datetime[utc]']) & \n",
    "        (merged_df['datetime[utc]'] < test_end)\n",
    "    ][['rained', 'dBAS_mean']]\n",
    "    \n",
    "    X_train, y_train = (\n",
    "    training_cla_df['dBAS_mean'].to_numpy().reshape(-1, 1), \n",
    "    training_cla_df['rained'].to_numpy()\n",
    ")\n",
    "    X_test, y_test = (\n",
    "        testing_cla_df['dBAS_mean'].to_numpy().reshape(-1, 1), \n",
    "        testing_cla_df['rained'].to_numpy()\n",
    "    )\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data1, testing_data1 = sep_train_test_data(merged_df1, (train_start, train_end), (test_start, test_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cla_df = merged_all_df[\n",
    "    (train_start <= merged_all_df['datetime[utc]']) & \n",
    "    (merged_all_df['datetime[utc]'] < train_end)\n",
    "][['rained', 'dBAS_mean_01', 'dBAS_mean_03', 'dBAS_mean_04']]\n",
    "\n",
    "testing_cla_df = merged_all_df[\n",
    "    (test_start <= merged_all_df['datetime[utc]']) & \n",
    "    (merged_all_df['datetime[utc]'] < test_end)\n",
    "][['rained', 'dBAS_mean_01', 'dBAS_mean_03', 'dBAS_mean_04']]\n",
    "\n",
    "training_data = (\n",
    "training_cla_df[['dBAS_mean_01', 'dBAS_mean_03', 'dBAS_mean_04']].to_numpy(),#.reshape(-1, 1), \n",
    "training_cla_df['rained'].to_numpy()\n",
    ")\n",
    "testing_data = (\n",
    "    testing_cla_df[['dBAS_mean_01', 'dBAS_mean_03', 'dBAS_mean_04']].to_numpy(),#.reshape(-1, 1), \n",
    "    testing_cla_df['rained'].to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification Node 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logistic = LogisticRegression()\n",
    "clf_logistic.fit(*training_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logistic.score(*testing_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data1[1], clf_logistic.predict(testing_data1[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification Nodes All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logistic = LogisticRegression()\n",
    "clf_logistic.fit(*training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logistic.score(*testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data[1], clf_logistic.predict(testing_data[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classification Node 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma='auto', class_weight='balanced')\n",
    "param_grid = {\n",
    "    'C': list(range(10, 31)),\n",
    "}\n",
    "clf_svm = GridSearchCV(svm, param_grid, cv=5)\n",
    "clf_svm.fit(*testing_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm.score(*training_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data1[1], clf_svm.predict(testing_data1[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classification Nodes All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma='auto', class_weight='balanced')\n",
    "param_grid = {\n",
    "    'C': list(range(10, 51)),\n",
    "}\n",
    "clf_svm = GridSearchCV(svm, param_grid, cv=5)\n",
    "clf_svm.fit(*training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm.score(*training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data[1], clf_svm.predict(testing_data[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification Node 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "param_grid = {\n",
    "    'max_depth': [2, 4, 8, 16, 32],\n",
    "    'n_estimators': [100, 200, 300, 400]\n",
    "}\n",
    "clf_rf = GridSearchCV(rf, param_grid, cv=5)\n",
    "clf_rf.fit(*training_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf.score(*testing_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data1[1], clf_rf.predict(testing_data1[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification Nodes All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "param_grid = {\n",
    "    'max_depth': [2, 4, 8, 16],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "clf_rf = GridSearchCV(rf, param_grid, cv=5)\n",
    "clf_rf.fit(*training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf.score(*testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testing_data[1], clf_rf.predict(testing_data[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:connections] *",
   "language": "python",
   "name": "conda-env-connections-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
